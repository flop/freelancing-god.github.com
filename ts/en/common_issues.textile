---
layout: ts_en
title: Common Questions and Issues
---

h2. Common Questions and Issues

Depending on how you have Sphinx setup, or what database you're using, you might come across little issues and curiosities. Here's a few to be aware of.

h3. Wildcard Searching

Sphinx can support wildcard searching (for example: Austr&lowast;), but it is turned off by default. To enable it, you need to add two settings to your config/sphinx.yml file:

{% highlight yaml %}
development:
  enable_star: 1
  min_infix_len: 1
test:
  enable_star: 1
  min_infix_len: 1
production:
  enable_star: 1
  min_infix_len: 1
{% endhighlight %}

You can set the min_infix_len value to something higher if you don't need single characters with a wildcard being matched. This may be a worthwhile fine-tuning, because the smaller the infixes are, the larger your index files become.

Don't forget to rebuild your Sphinx indexes after making this change.

{% highlight sh %}
rake thinking_sphinx:rebuild
{% endhighlight %}

h3. Slow Indexing

If Sphinx is taking a while to process all your records, there are a few common reasons for this happening. Firstly, make sure you have database indexes on any foreign key columns and any columns you filter or sort by.

Secondly - are you using fixtures? Rails' fixtures have randomly generated IDs, which are usually extremely large integers, and Sphinx isn't set up to process disparate IDs efficiently by default. To get around this, you'll need to set *sql_range_step* in your config/sphinx.yml file for the appropriate environments:

{% highlight yaml %}
development:
  sql_range_step: 10000000
{% endhighlight %}

h3. MySQL and Large Fields

If you've got a field that is built off multiple values in one column - ie: through a has_many association - then you may hit MySQL's default limit for string concatenation: 1024 characters. You can increase the "group_concat_max_len":http://dev.mysql.com/doc/refman/5.1/en/server-system-variables.html#sysvar_group_concat_max_len value by adding the following to your define_index block:

{% highlight rb %}
define_index do
  # ...
  
  set_property :group_concat_max_len => 8192
end
{% endhighlight %}

If these fields get particularly large though, then there's another setting you may need to set in your MySQL configuration: "max_allowed_packet":http://dev.mysql.com/doc/refman/5.1/en/server-system-variables.html#sysvar_max_allowed_packet, which has a default of sixteen megabytes. You can't set this option via Thinking Sphinx though (it's a rare edge case).

h3. PostgreSQL with Manual Fields and Attributes

If you're using fields or attributes defined by strings (raw SQL), then the columns used in them aren't automatically included in the GROUP BY clause of the generated SQL statement. To make sure the query is valid, you will need to explicitly add these columns to the GROUP BY clause.

A common example is if you're converting latitude and longitude columns from degrees to radians via SQL.

notextile.. {% highlight rb %}
define_index do
  # ...
  
  has "RADIANS(latitude)",  :as => :latitude,  :type => :float
  has "RADIANS(longitude)", :as => :longitude, :type => :float
  
  group_by "latitude", "longitude"
end
{% endhighlight %}

h3. Delta Indexing Not Working

Often people find delta indexing isn't working on their production server. Sometimes, this is because Sphinx is running as one user on the system, and the Rails/Merb application is being served as a different user. Check your production.log file for mentions of permissions issues to confirm this.

Indexing for deltas is invoked by the web user, and so needs to have access to the index files. The simplest way to ensure this is run all Thinking Sphinx rake tasks by that web user.

If you're still having issues, and you're using Passenger, read the next hint.

h3. Running Delta Indexing with Passenger

If you're using Phusion Passenger on your production server, with delta indexing on some models, a common issue people find is that their delta indexes don't get processed.

If it's not a permissions issue (see the previous hint), another common cause is because Passenger has it's own PATH set up, and can't execute the Sphinx binaries (indexer and searchd) implicitly.

The way around this is to find out where your binaries are on the server:

{% highlight sh %}
which searchd
{% endhighlight %}

And then set the bin_path option in your config/sphinx.yml file for the production environment:

{% highlight yaml %}
production:
  bin_path: '/usr/local/bin'
{% endhighlight %}

h3. Can only access the first thousand search results

This is actually how Sphinx is supposed to behave. Have a read of the "Large Result Sets section of the Advanced Configuration page":advanced_config.html#large-result-sets to see why, and how to work around it if you really need to.
